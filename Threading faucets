import time
import threading
import logging

class TokenFaucet:
    def __init__(self, initial_tokens=100, data_flow_rate=1):
        self.tokens = initial_tokens
        self.data_flow_rate = data_flow_rate
        self.running = False
        self.callback = None

    def start(self):
        self.running = True
        threading.Thread(target=self._update_tokens).start()

    def stop(self):
        self.running = False

    def set_callback(self, callback):
        self.callback = callback

    def _update_tokens(self):
        while self.running:
            try:
                # Simulate data refinement process
                time.sleep(1)
                # Generate more tokens based on the data flow rate
                self.tokens += self.data_flow_rate
                logging.info(f"Tokens updated: {self.tokens}")
                # Notify callback function if available
                if self.callback:
                    self.callback(self.tokens)
            except Exception as e:
                logging.error(f"Error updating tokens: {e}")

if __name__ == "__main__":
    # Initialize logger
    logging.basicConfig(level=logging.INFO)

    # Define callback function to handle token updates
    def handle_token_update(tokens):
        print(f"Received token update: {tokens}")

    # Create an instance of TokenFaucet with custom data flow rate
    faucet = TokenFaucet(data_flow_rate=2)

    # Set the callback function
    faucet.set_callback(handle_token_update)

    # Start the token faucet
    faucet.start()

    try:
        # Simulate data refinement process for 10 seconds
        time.sleep(10)
    finally:
        # Stop the faucet after simulation
        faucet.stop()
